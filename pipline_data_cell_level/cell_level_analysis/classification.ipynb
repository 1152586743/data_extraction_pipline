{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e042fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /Users/yhu10/Desktop/VLM/pipline_data_cell_level/cell_level_analysis/CMU-2/detections_prediction.txt\n"
     ]
    }
   ],
   "source": [
    "# ===== 必改：按你的本机路径与切片名修改 =====\n",
    "tsv_path = \"/Users/yhu10/Desktop/VLM/pipline_data_cell_level/measurements.tsv\"   # 你的 QuPath 导出\n",
    "case_id  = \"CMU-2\"                                        # 例如 CMU-2.svs -> \"CMU-2\"\n",
    "data_dir = \"/Users/yhu10/Desktop/VLM/pipline_data_cell_level/cell_level_analysis\" # Groovy 会从 data_dir/<case_id>/ 读取\n",
    "# ==============================================\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "LABEL_COL = \"Classification\"   # 你 TSV 中已有的标签列\n",
    "\n",
    "# 1) 读取 TSV\n",
    "df = pd.read_csv(tsv_path, sep=\"\\t\")\n",
    "\n",
    "# 2) 清洗标签（统一大小写/空白 & 合并同义词，可按需扩展）\n",
    "def _norm(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    s = str(x).strip().lower()\n",
    "    return np.nan if s in (\"\", \"nan\") else s\n",
    "df[LABEL_COL] = df[LABEL_COL].map(_norm)\n",
    "\n",
    "alias = {\n",
    "    \"stroma\":\"Stroma\", \"stromal\":\"Stroma\",\n",
    "    \"immune\":\"Immune\", \"immune cell\":\"Immune\", \"immune cells\":\"Immune\"\n",
    "}\n",
    "df[LABEL_COL] = df[LABEL_COL].map(lambda s: alias.get(s, s.title() if isinstance(s,str) else s))\n",
    "\n",
    "# 3) 选择特征（排除明显非特征列）\n",
    "needed = [\"Centroid X µm\",\"Centroid Y µm\"]\n",
    "for c in needed:\n",
    "    if c not in df.columns:\n",
    "        raise ValueError(f\"缺少必需列：{c}（导出测量时要包含质心坐标，单位µm）\")\n",
    "\n",
    "drop = {LABEL_COL, *needed, \"ID\",\"Name\",\"ROI\",\"Image\",\"Path\",\"Parent\",\"Tile\",\"X\",\"Y\"}\n",
    "drop = {c for c in drop if c in df.columns}\n",
    "feat_cols = [c for c in df.columns if c not in drop and pd.api.types.is_numeric_dtype(df[c])]\n",
    "assert len(feat_cols)>0, \"没有可用数值特征列，请检查 TSV。\"\n",
    "X = df[feat_cols].fillna(0.0).to_numpy()\n",
    "\n",
    "# 4) 训练（仅用已标注行），并预测所有细胞\n",
    "is_lab = df[LABEL_COL].notna()\n",
    "if not is_lab.any():\n",
    "    raise ValueError(\"没有任何已标注细胞，无法训练。请先在 TSV 的 classification 列留少量标签。\")\n",
    "\n",
    "y_lab = df.loc[is_lab, LABEL_COL].astype(str)\n",
    "\n",
    "try:\n",
    "    # 优先 XGBoost（安装失败自动回退）\n",
    "    from xgboost import XGBClassifier\n",
    "    clf = XGBClassifier(\n",
    "        n_estimators=600, max_depth=6, learning_rate=0.05,\n",
    "        subsample=0.9, colsample_bytree=0.9,\n",
    "        n_jobs=4, eval_metric=\"mlogloss\", random_state=42\n",
    "    )\n",
    "    clf.fit(X[is_lab], y_lab)\n",
    "    proba = clf.predict_proba(X); classes = clf.classes_\n",
    "except Exception:\n",
    "    from sklearn.pipeline import make_pipeline\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.svm import SVC\n",
    "    clf = make_pipeline(StandardScaler(with_mean=True),\n",
    "                        SVC(kernel=\"rbf\", probability=True, class_weight=\"balanced\"))\n",
    "    clf.fit(X[is_lab], y_lab)\n",
    "    proba = clf.predict_proba(X); classes = clf.classes_\n",
    "\n",
    "idx      = proba.argmax(1)\n",
    "y_pred   = classes[idx]\n",
    "y_score  = proba.max(1)\n",
    "\n",
    "# 5) 导出 detections_prediction.txt（无表头；列序固定）\n",
    "cx = df[\"Centroid X µm\"].to_numpy()\n",
    "cy = df[\"Centroid Y µm\"].to_numpy()\n",
    "\n",
    "out_dir = Path(data_dir) / case_id\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "det = pd.DataFrame({\n",
    "    \"id\": np.arange(len(df)),\n",
    "    \"score\": np.round(y_score, 4),  # 置信度（可用于后续过滤）\n",
    "    \"label\": y_pred,                # Groovy index=2\n",
    "    \"reserved\": 0,                  # 占位\n",
    "    \"Centroid X µm\": cx,            # Groovy index=4\n",
    "    \"Centroid Y µm\": cy             # Groovy index=5\n",
    "})\n",
    "det_path = out_dir / \"detections_prediction.txt\"\n",
    "det.to_csv(det_path, sep=\"\\t\", index=False, header=False)\n",
    "print(\"Wrote:\", det_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eba031ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "未安装 umap-learn，已用 PCA 代替\n",
      "Wrote: /Users/yhu10/Desktop/VLM/pipline_data_cell_level/cell_level_analysis/CMU-2_cell_feature_umap.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yhu10/Library/Python/3.9/lib/python/site-packages/sklearn/decomposition/_pca.py:606: RuntimeWarning: divide by zero encountered in matmul\n",
      "  C = X.T @ X\n",
      "/Users/yhu10/Library/Python/3.9/lib/python/site-packages/sklearn/decomposition/_pca.py:606: RuntimeWarning: overflow encountered in matmul\n",
      "  C = X.T @ X\n",
      "/Users/yhu10/Library/Python/3.9/lib/python/site-packages/sklearn/decomposition/_pca.py:606: RuntimeWarning: invalid value encountered in matmul\n",
      "  C = X.T @ X\n",
      "/Users/yhu10/Library/Python/3.9/lib/python/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: divide by zero encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/yhu10/Library/Python/3.9/lib/python/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: overflow encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/yhu10/Library/Python/3.9/lib/python/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: invalid value encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n"
     ]
    }
   ],
   "source": [
    "# ===== 改这里：按你的路径与切片名 =====\n",
    "tsv_path   = \"/Users/yhu10/Desktop/VLM/pipline_data_cell_level/measurements.tsv\"                 # QuPath 导出的 measurements.tsv\n",
    "case_id    = \"CMU-2\"                                                      # 你的切片名（去扩展名）\n",
    "out_dir    = \"/Users/yhu10/Desktop/VLM/pipline_data_cell_level/cell_level_analysis\"              # UMAP TSV 输出目录（= marimo 的 csv_path_root）\n",
    "pred_path  = f\"/Users/yhu10/Desktop/VLM/pipline_data_cell_level/cell_level_analysis/{case_id}/detections_prediction.txt\"  # 我们已生成的预测文件\n",
    "# ====================================\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# 1) 读取测量表\n",
    "df = pd.read_csv(tsv_path, sep=\"\\t\")\n",
    "\n",
    "# 2) 读取预测label（第3列=label；第5/6列是 Centroid X/Y µm）\n",
    "pred = pd.read_csv(pred_path, sep=\"\\t\", header=None,\n",
    "                   names=[\"id\",\"score\",\"label\",\"reserved\",\"Centroid X µm\",\"Centroid Y µm\"])\n",
    "\n",
    "# 如果 measurements.tsv 里也有 Centroid X/Y µm，优先用 measurements 里的坐标（更全）\n",
    "if \"Centroid X µm\" in df.columns and \"Centroid Y µm\" in df.columns:\n",
    "    cx = df[\"Centroid X µm\"].to_numpy()\n",
    "    cy = df[\"Centroid Y µm\"].to_numpy()\n",
    "else:\n",
    "    cx = pred[\"Centroid X µm\"].to_numpy()\n",
    "    cy = pred[\"Centroid Y µm\"].to_numpy()\n",
    "\n",
    "labels = pred[\"label\"].astype(str).to_numpy()\n",
    "\n",
    "# 3) 选数值特征做降维（排除明显非特征列）\n",
    "drop = {\"Centroid X µm\",\"Centroid Y µm\",\"ID\",\"Name\",\"ROI\",\"Image\",\"Path\",\n",
    "        \"Parent\",\"Tile\",\"X\",\"Y\",\"Object ID\",\"Object type\",\"Classification\",\"PathClass\",\n",
    "        \"classification\",\"class\",\"label\",\"Combined_Cluster\"}\n",
    "feat_cols = [c for c in df.columns if c not in drop and pd.api.types.is_numeric_dtype(df[c])]\n",
    "assert len(feat_cols) > 0, \"没有可用的数值特征列，请检查 measurements.tsv\"\n",
    "\n",
    "X = df[feat_cols].fillna(0.0).to_numpy()\n",
    "\n",
    "# 4) 计算 UMAP（若未装 umap-learn，则回退到 PCA）\n",
    "try:\n",
    "    import umap\n",
    "    emb = umap.UMAP(n_components=2, n_neighbors=15, min_dist=0.1, random_state=42).fit_transform(X)\n",
    "    print(\"UMAP 完成\")\n",
    "except Exception:\n",
    "    from sklearn.decomposition import PCA\n",
    "    emb = PCA(n_components=2, random_state=42).fit_transform(X)\n",
    "    print(\"未安装 umap-learn，已用 PCA 代替\")\n",
    "\n",
    "# 5) 按 marimo 需求导出 TSV：<case_id>_cell_feature_umap.tsv\n",
    "umap_df = pd.DataFrame({\n",
    "    \"umap_x\": emb[:,0],\n",
    "    \"umap_y\": emb[:,1],\n",
    "    \"Centroid X µm\": cx,\n",
    "    \"Centroid Y µm\": cy,\n",
    "    \"Combined_Cluster\": labels  # marimo 代码里当作类别列\n",
    "})\n",
    "\n",
    "out_path = Path(out_dir) / f\"{case_id}_cell_feature_umap.tsv\"\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "umap_df.to_csv(out_path, sep=\"\\t\", index=False)\n",
    "print(\"Wrote:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f065ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-21.0.0-cp39-cp39-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Downloading pyarrow-21.0.0-cp39-cp39-macosx_12_0_arm64.whl (31.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.2/31.2 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0mm0:00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: pyarrow\n",
      "Successfully installed pyarrow-21.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c137d9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
